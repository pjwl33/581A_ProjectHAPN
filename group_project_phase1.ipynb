{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow and other necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from data/training/\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unknown url type: 'data/training/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset_url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata/training/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m data_dir \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mget_file(\n\u001b[1;32m      3\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mphotos\u001b[39;49m\u001b[39m'\u001b[39;49m, origin\u001b[39m=\u001b[39;49mdataset_url, untar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      4\u001b[0m data_dir \u001b[39m=\u001b[39m pathlib\u001b[39m.\u001b[39mPath(data_dir)\n\u001b[1;32m      6\u001b[0m data_dir \u001b[39m=\u001b[39m pathlib\u001b[39m.\u001b[39mPath(dataset_url)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/data_utils.py:296\u001b[0m, in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 296\u001b[0m         urlretrieve(origin, fpath, DLProgbar())\n\u001b[1;32m    297\u001b[0m     \u001b[39mexcept\u001b[39;00m urllib\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mHTTPError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    298\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(error_msg\u001b[39m.\u001b[39mformat(origin, e\u001b[39m.\u001b[39mcode, e\u001b[39m.\u001b[39mmsg))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/data_utils.py:84\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m response \u001b[39m=\u001b[39m urlopen(url, data)\n\u001b[1;32m     85\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(filename, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m fd:\n\u001b[1;32m     86\u001b[0m     \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunk_read(response, reporthook\u001b[39m=\u001b[39mreporthook):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:503\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mself\u001b[39m, fullurl, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, timeout\u001b[39m=\u001b[39msocket\u001b[39m.\u001b[39m_GLOBAL_DEFAULT_TIMEOUT):\n\u001b[1;32m    501\u001b[0m     \u001b[39m# accept a URL or a Request object\u001b[39;00m\n\u001b[1;32m    502\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fullurl, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 503\u001b[0m         req \u001b[39m=\u001b[39m Request(fullurl, data)\n\u001b[1;32m    504\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m         req \u001b[39m=\u001b[39m fullurl\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:322\u001b[0m, in \u001b[0;36mRequest.__init__\u001b[0;34m(self, url, data, headers, origin_req_host, unverifiable, method)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, headers\u001b[39m=\u001b[39m{},\n\u001b[1;32m    320\u001b[0m              origin_req_host\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, unverifiable\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    321\u001b[0m              method\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 322\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfull_url \u001b[39m=\u001b[39m url\n\u001b[1;32m    323\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheaders \u001b[39m=\u001b[39m {}\n\u001b[1;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munredirected_hdrs \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:348\u001b[0m, in \u001b[0;36mRequest.full_url\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_full_url \u001b[39m=\u001b[39m unwrap(url)\n\u001b[1;32m    347\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_full_url, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfragment \u001b[39m=\u001b[39m _splittag(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_full_url)\n\u001b[0;32m--> 348\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/urllib/request.py:377\u001b[0m, in \u001b[0;36mRequest._parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype, rest \u001b[39m=\u001b[39m _splittype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_full_url)\n\u001b[1;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 377\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munknown url type: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfull_url)\n\u001b[1;32m    378\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselector \u001b[39m=\u001b[39m _splithost(rest)\n\u001b[1;32m    379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost:\n",
      "\u001b[0;31mValueError\u001b[0m: unknown url type: 'data/training/'"
     ]
    }
   ],
   "source": [
    "dataset_url = \"data/training/\"\n",
    "data_dir = pathlib.Path(dataset_url)\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.jpg'))) + \\\n",
    "    len(list(data_dir.glob('*/*.png'))) + len(list(data_dir.glob('*/*.jpeg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/training\n",
      "Found 0 files belonging to 0 classes.\n",
      "Using 0 files for training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No images found in directory data/training. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(data_dir)\n\u001b[1;32m      8\u001b[0m \u001b[39m# Train Split at 80%\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m train_ds \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mimage_dataset_from_directory(\n\u001b[1;32m     10\u001b[0m     data_dir,\n\u001b[1;32m     11\u001b[0m     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m     subset\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m     seed\u001b[39m=\u001b[39;49m\u001b[39m123\u001b[39;49m,\n\u001b[1;32m     14\u001b[0m     image_size\u001b[39m=\u001b[39;49m(img_height, img_width),\n\u001b[1;32m     15\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size)\n\u001b[1;32m     17\u001b[0m \u001b[39m# Validation of the data at 80%\u001b[39;00m\n\u001b[1;32m     18\u001b[0m val_ds \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mimage_dataset_from_directory(\n\u001b[1;32m     19\u001b[0m     data_dir,\n\u001b[1;32m     20\u001b[0m     validation_split\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     image_size\u001b[39m=\u001b[39m(img_height, img_width),\n\u001b[1;32m     24\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/image_dataset.py:294\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m image_paths, labels \u001b[39m=\u001b[39m dataset_utils\u001b[39m.\u001b[39mget_training_or_validation_split(\n\u001b[1;32m    291\u001b[0m     image_paths, labels, validation_split, subset\n\u001b[1;32m    292\u001b[0m )\n\u001b[1;32m    293\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m image_paths:\n\u001b[0;32m--> 294\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    295\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo images found in directory \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    296\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAllowed formats: \u001b[39m\u001b[39m{\u001b[39;00mALLOWLIST_FORMATS\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    299\u001b[0m dataset \u001b[39m=\u001b[39m paths_and_labels_to_dataset(\n\u001b[1;32m    300\u001b[0m     image_paths\u001b[39m=\u001b[39mimage_paths,\n\u001b[1;32m    301\u001b[0m     image_size\u001b[39m=\u001b[39mimage_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m     crop_to_aspect_ratio\u001b[39m=\u001b[39mcrop_to_aspect_ratio,\n\u001b[1;32m    308\u001b[0m )\n\u001b[1;32m    309\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mprefetch(tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mAUTOTUNE)\n",
      "\u001b[0;31mValueError\u001b[0m: No images found in directory data/training. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
     ]
    }
   ],
   "source": [
    "# Image Loader Params\n",
    "batch_size = 64\n",
    "img_height = 120\n",
    "img_width = 128\n",
    "\n",
    "print(data_dir)\n",
    "\n",
    "# Train Split at 80%\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# Validation of the data at 80%\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification of names - each image type in its own dir\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "\n",
    "# Visualize the images\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic Keras Model\n",
    "\n",
    "# The Keras Sequential model consists of three convolution blocks(tf.keras.layers.Conv2D)\n",
    "# with a max pooling layer(tf.keras.layers.MaxPooling2D) in each of them.\n",
    "#\n",
    "# There's a fully-connected layer (tf.keras.layers.Dense) with 128 units on top of it that\n",
    "# is activated by a ReLU activation function ('relu').\n",
    "#\n",
    "# This model has not been tuned for high accuracy; the goal of this tutorial is to show a standard approach.\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "# For this tutorial, choose the tf.keras.optimizers.Adam optimizer and\n",
    "# tf.keras.losses.SparseCategoricalCrossentropy loss function.\n",
    "#\n",
    "# To view training and validation accuracy for each training epoch, pass the metrics argument to Model.compile.\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                  from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Show the Model Summary - need to look into what this means\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Training Results in Plot Forms\n",
    "def visualization_report(history, epochs=10):\n",
    "  acc = history.history['accuracy']\n",
    "  val_acc = history.history['val_accuracy']\n",
    "\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs_range = range(epochs)\n",
    "\n",
    "  plt.figure(figsize=(8, 8))\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "  plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "  plt.legend(loc='lower right')\n",
    "  plt.title('Training and Validation Accuracy')\n",
    "\n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.plot(epochs_range, loss, label='Training Loss')\n",
    "  plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "  plt.legend(loc='upper right')\n",
    "  plt.title('Training and Validation Loss')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "visualization_report(history, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunflower_path = \"data/predictions/Red_sunflower\"\n",
    "rose_path = \"data/predictions/rose.jpeg\"\n",
    "tulip_path = \"data/predictions/tulips.jpeg\"\n",
    "\n",
    "paths = [sunflower_path, rose_path, tulip_path]\n",
    "\n",
    "for p in paths:\n",
    "    img = tf.keras.utils.load_img(\n",
    "        p, target_size=(img_height, img_width)\n",
    "    )\n",
    "    img_array = tf.keras.utils.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create a batch\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "    print(\n",
    "        \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "        .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
